export chapter_04_step_000="$(tput bold)\n$(head -n1 ~/Project/hands-on-music-generation-with-magenta/Chapter04/README.md | figlet)\n"

export chapter_04_step_001="$(tput bold)\n\t$(tput setab 0)$(tput setaf 7) 0. $(tput sgr 0) $(tput bold)Hello ðŸ‘‹ðŸ˜ƒ Welcome to the Chapter 4 action video!\n\tFirst, lets change directory to chapter 04 in the book's code.\n"

export chapter_04_step_002="$(tput bold)\n\t$(tput setab 0)$(tput setaf 7) 1. $(tput sgr 0) $(tput bold)Lets have a look at the 'chapter_04_example_01.py' example, which shows how to sample,\n\tinterpolate and humanize a drums sequence using MusicVAE and various configurations.\n"

export chapter_04_step_003="$(tput bold)\n\t$(tput setab 0)$(tput setaf 7) 2. $(tput sgr 0) $(tput bold)We execute the code of our example, which will generate a humanized (groovy)\n\tdrum sequence ðŸŽ¼. We need to make sure that we are in the conda 'magenta' environment first.\n"

export chapter_04_step_004="$(tput bold)\n\t$(tput setab 0)$(tput setaf 7) 3. $(tput sgr 0) $(tput bold)Lets open a browser window and look at the generated sequence.\n"

export chapter_04_step_005="$(tput bold)\n\t$(tput setab 0)$(tput setaf 7) 4. $(tput sgr 0) $(tput bold)Finally, we listen the generated MIDI using FluidSynth ðŸŽ¶.\n"

export chapter_04_step_006="$(tput bold)\n\t$(tput setab 0)$(tput setaf 7) 5. $(tput sgr 0) $(tput bold)ðŸ’ª\n"

