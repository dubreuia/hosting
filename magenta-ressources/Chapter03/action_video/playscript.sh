export chapter_03_step_000="$(tput bold)\n$(head -n1 ~/Project/hands-on-music-generation-with-magenta/Chapter03/README.md | figlet)\n"

export chapter_03_step_001="$(tput bold)\n\t$(tput setab 0)$(tput setaf 7) 0. $(tput sgr 0) $(tput bold)Hello ðŸ‘‹ðŸ˜ƒ Welcome to the Chapter 3 action video!\n\tFirst, lets change directory to chapter 03 in the book's code.\n"

export chapter_03_step_002="$(tput bold)\n\t$(tput setab 0)$(tput setaf 7) 1. $(tput sgr 0) $(tput bold)Lets have a look at the 'chapter_03_example_01.py' example, which shows a\n\tmelody (monophonic) generation using the Melody RNN model and\n\t3 configurations: basic, lookback and attention.\n"

export chapter_03_step_003="$(tput bold)\n\t$(tput setab 0)$(tput setaf 7) 2. $(tput sgr 0) $(tput bold)We execute the code of our example, which will generate 3 sequences ðŸŽ¼. We need\n\tto make sure that we are in the conda 'magenta' environment first.\n"

export chapter_03_step_004="$(tput bold)\n\t$(tput setab 0)$(tput setaf 7) 3. $(tput sgr 0) $(tput bold)Lets open a browser window and look at the generated sequences.\n"

export chapter_03_step_005="$(tput bold)\n\t$(tput setab 0)$(tput setaf 7) 4. $(tput sgr 0) $(tput bold)Finally, we listen to one of the generated MIDI using FluidSynth ðŸŽ¶.\n"

export chapter_03_step_006="$(tput bold)\n\t$(tput setab 0)$(tput setaf 7) 5. $(tput sgr 0) $(tput bold)ðŸ’ª\n"

